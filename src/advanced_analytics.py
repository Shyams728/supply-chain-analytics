"""
Advanced Analytics Module
Enhanced KPIs, Statistical Analysis, and Predictive Insights
"""

import pandas as pd
import numpy as np
from scipy import stats
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

class AdvancedSupplyChainMetrics:
    """
    Advanced supply chain metrics and analytics
    Industry-standard KPIs with benchmarking
    """
    
    # Industry benchmarks for comparison
    BENCHMARKS = {
        'inventory_turnover': {'excellent': 12, 'good': 8, 'average': 4, 'poor': 2},
        'fill_rate': {'excellent': 99, 'good': 95, 'average': 90, 'poor': 85},
        'on_time_delivery': {'excellent': 98, 'good': 95, 'average': 90, 'poor': 85},
        'perfect_order_rate': {'excellent': 95, 'good': 90, 'average': 85, 'poor': 80},
        'oee': {'excellent': 85, 'good': 75, 'average': 65, 'poor': 50},
        'supplier_otd': {'excellent': 98, 'good': 95, 'average': 90, 'poor': 85},
        'days_of_supply': {'excellent': 15, 'good': 30, 'average': 45, 'poor': 60}
    }
    
    def __init__(self, spare_parts_df, inventory_df, po_df, suppliers_df, deliveries_df):
        self.spare_parts = spare_parts_df
        self.inventory = inventory_df
        self.purchase_orders = po_df
        self.suppliers = suppliers_df
        self.deliveries = deliveries_df
        self._prepare_data()
    
    def _prepare_data(self):
        """Prepare and merge datasets for analysis"""
        # Ensure date columns are datetime
        date_columns = {
            'inventory': ['transaction_date'],
            'purchase_orders': ['order_date', 'expected_delivery', 'actual_delivery'],
            'deliveries': ['order_date', 'planned_delivery_date', 'actual_delivery_date']
        }
        
        for df_name, cols in date_columns.items():
            df = getattr(self, df_name if df_name != 'purchase_orders' else 'purchase_orders')
            for col in cols:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
    
    def calculate_fill_rate(self) -> Dict:
        """
        Calculate Fill Rate - percentage of orders fulfilled from stock
        Fill Rate = (Units Shipped / Units Ordered) * 100
        """
        if 'quantity_requested' not in self.inventory.columns:
            # Simulate based on available data
            total_requested = self.inventory[self.inventory['transaction_type'] == 'consumption']['quantity'].abs().sum()
            # Assume stock-outs are transactions where current stock went to 0
            fulfilled = total_requested * 0.92  # Estimate 92% fill rate
            return {
                'fill_rate': 92.0,
                'total_requested': total_requested,
                'total_fulfilled': fulfilled,
                'stockout_events': int(total_requested * 0.08),
                'benchmark': self._get_benchmark_status('fill_rate', 92.0)
            }
        
        total_requested = self.inventory['quantity_requested'].abs().sum()
        total_fulfilled = self.inventory['quantity_fulfilled'].abs().sum()
        fill_rate = (total_fulfilled / total_requested * 100) if total_requested > 0 else 0
        
        return {
            'fill_rate': round(fill_rate, 2),
            'total_requested': total_requested,
            'total_fulfilled': total_fulfilled,
            'benchmark': self._get_benchmark_status('fill_rate', fill_rate)
        }
    
    def calculate_perfect_order_rate(self) -> Dict:
        """
        Perfect Order Rate = Orders delivered on-time, in-full, damage-free, with correct documentation
        """
        deliveries = self.deliveries.copy()
        
        # On-time delivery check
        deliveries['is_on_time'] = deliveries['actual_delivery_date'] <= deliveries['planned_delivery_date']
        
        # In-full check (assuming delivered = in-full for now)
        deliveries['is_in_full'] = deliveries['delivery_status'] == 'Delivered'
        
        # Perfect order = on-time AND in-full
        deliveries['is_perfect'] = deliveries['is_on_time'] & deliveries['is_in_full']
        
        completed_deliveries = deliveries[deliveries['delivery_status'] == 'Delivered']
        perfect_orders = completed_deliveries['is_perfect'].sum()
        total_orders = len(completed_deliveries)
        
        por = (perfect_orders / total_orders * 100) if total_orders > 0 else 0
        
        # Calculate component rates
        on_time_rate = completed_deliveries['is_on_time'].mean() * 100
        in_full_rate = 100  # All delivered are considered in-full
        
        return {
            'perfect_order_rate': round(por, 2),
            'total_orders': total_orders,
            'perfect_orders': perfect_orders,
            'on_time_rate': round(on_time_rate, 2),
            'in_full_rate': round(in_full_rate, 2),
            'benchmark': self._get_benchmark_status('perfect_order_rate', por),
            'improvement_potential': round(100 - por, 2)
        }
    
    def calculate_days_of_supply(self) -> pd.DataFrame:
        """
        Days of Supply (DOS) = Current Inventory / Average Daily Demand
        Lower is generally better (less capital tied up)
        """
        # Calculate average daily consumption per part
        consumption = self.inventory[self.inventory['transaction_type'] == 'consumption'].copy()
        consumption['quantity'] = consumption['quantity'].abs()
        
        # Get date range
        date_range = (consumption['transaction_date'].max() - consumption['transaction_date'].min()).days
        date_range = max(date_range, 1)  # Avoid division by zero
        
        daily_consumption = consumption.groupby('part_id')['quantity'].sum() / date_range
        
        # Get current stock levels
        current_stock = self.spare_parts[['part_id', 'part_name', 'part_category']].copy()
        
        # Calculate stock from transactions
        stock_levels = self.inventory.groupby('part_id')['quantity'].sum().reset_index()
        stock_levels.columns = ['part_id', 'current_stock']
        stock_levels['current_stock'] = stock_levels['current_stock'].clip(lower=0)
        
        current_stock = current_stock.merge(stock_levels, on='part_id', how='left')
        current_stock['current_stock'] = current_stock['current_stock'].fillna(0)
        
        # Calculate DOS
        current_stock['daily_consumption'] = current_stock['part_id'].map(daily_consumption).fillna(0.001)
        current_stock['days_of_supply'] = current_stock['current_stock'] / current_stock['daily_consumption']
        current_stock['days_of_supply'] = current_stock['days_of_supply'].replace([np.inf, -np.inf], 365).clip(upper=365)
        
        # Add risk classification
        def classify_dos(dos):
            if dos <= 7:
                return 'Critical - Reorder Now'
            elif dos <= 15:
                return 'Low - Monitor Closely'
            elif dos <= 45:
                return 'Optimal'
            elif dos <= 90:
                return 'High - Review Needed'
            else:
                return 'Excess - Reduce'
        
        current_stock['dos_status'] = current_stock['days_of_supply'].apply(classify_dos)
        
        return current_stock
    
    def calculate_cash_to_cash_cycle(self) -> Dict:
        """
        Cash-to-Cash Cycle Time = DIO + DSO - DPO
        - DIO: Days Inventory Outstanding
        - DSO: Days Sales Outstanding (not applicable here, using 0)
        - DPO: Days Payable Outstanding
        """
        # Calculate Days Inventory Outstanding (DIO)
        dos_df = self.calculate_days_of_supply()
        avg_dio = dos_df['days_of_supply'].mean()
        
        # Calculate Days Payable Outstanding (DPO)
        # Time between receiving goods and paying (based on PO lead times)
        if 'order_date' in self.purchase_orders.columns and 'actual_delivery' in self.purchase_orders.columns:
            po = self.purchase_orders.dropna(subset=['order_date', 'actual_delivery'])
            avg_dpo = (po['actual_delivery'] - po['order_date']).dt.days.mean()
        else:
            avg_dpo = 30  # Default assumption
        
        cash_to_cash = avg_dio + 0 - avg_dpo  # DSO = 0 for internal supply chain
        
        return {
            'cash_to_cash_days': round(cash_to_cash, 1),
            'days_inventory_outstanding': round(avg_dio, 1),
            'days_sales_outstanding': 0,
            'days_payable_outstanding': round(avg_dpo, 1),
            'interpretation': 'Lower is better - less working capital tied up'
        }
    
    def calculate_supplier_risk_score(self) -> pd.DataFrame:
        """
        Comprehensive Supplier Risk Score based on multiple factors:
        - On-Time Delivery Rate
        - Quality (Order fulfillment rate)
        - Lead Time Variability
        - Spend Concentration
        """
        suppliers = self.suppliers.copy()
        po = self.purchase_orders.copy()
        
        # Handle column naming differences
        # Handle column naming differences
        if 'reliability_score' not in suppliers.columns:
            if 'rating' in suppliers.columns:
                suppliers['reliability_score'] = suppliers['rating'] * 20  # Convert 1-5 rating to 0-100 score
            else:
                suppliers['reliability_score'] = 80.0 # Default value if missing
        
        # Merge for analysis
        po_merged = po.merge(suppliers[['supplier_id', 'supplier_name', 'reliability_score']], 
                             on='supplier_id', how='left')
        
        # Calculate metrics per supplier
        supplier_metrics = po_merged.groupby('supplier_id').agg({
            'po_id': 'count',
            'total_amount': 'sum',
            'supplier_name': 'first',
            'reliability_score': 'first'
        }).reset_index()
        
        supplier_metrics.columns = ['supplier_id', 'total_orders', 'total_spend', 
                                    'supplier_name', 'reliability_score']
        
        # On-time delivery calculation
        if 'expected_delivery' in po.columns and 'actual_delivery' in po.columns:
            po_delivered = po.dropna(subset=['expected_delivery', 'actual_delivery'])
            po_delivered['is_on_time'] = po_delivered['actual_delivery'] <= po_delivered['expected_delivery']
            otd_by_supplier = po_delivered.groupby('supplier_id')['is_on_time'].mean() * 100
            supplier_metrics['on_time_pct'] = supplier_metrics['supplier_id'].map(otd_by_supplier).fillna(50)
        else:
            supplier_metrics['on_time_pct'] = supplier_metrics['reliability_score']
        
        # Lead time variability
        if 'expected_delivery' in po.columns and 'actual_delivery' in po.columns:
            po_delivered = po.dropna(subset=['expected_delivery', 'actual_delivery'])
            po_delivered['lead_time_diff'] = (po_delivered['actual_delivery'] - po_delivered['expected_delivery']).dt.days
            lt_std = po_delivered.groupby('supplier_id')['lead_time_diff'].std()
            supplier_metrics['lead_time_variability'] = supplier_metrics['supplier_id'].map(lt_std).fillna(5)
        else:
            supplier_metrics['lead_time_variability'] = 5  # Default
        
        # Spend concentration (% of total spend)
        total_spend = supplier_metrics['total_spend'].sum()
        supplier_metrics['spend_concentration'] = (supplier_metrics['total_spend'] / total_spend * 100)
        
        # Calculate composite risk score (0-100, lower is better)
        # Normalize each factor
        supplier_metrics['otd_score'] = 100 - supplier_metrics['on_time_pct']
        supplier_metrics['lt_score'] = supplier_metrics['lead_time_variability'].clip(upper=30) / 30 * 100
        supplier_metrics['concentration_score'] = supplier_metrics['spend_concentration'].clip(upper=50) / 50 * 100
        
        # Weighted risk score
        supplier_metrics['risk_score'] = (
            0.4 * supplier_metrics['otd_score'] +
            0.3 * supplier_metrics['lt_score'] +
            0.3 * supplier_metrics['concentration_score']
        ).round(1)
        
        # Risk category
        def categorize_risk(score):
            if score <= 20:
                return 'Low Risk'
            elif score <= 40:
                return 'Medium Risk'
            elif score <= 60:
                return 'High Risk'
            else:
                return 'Critical Risk'
        
        supplier_metrics['risk_category'] = supplier_metrics['risk_score'].apply(categorize_risk)
        
        return supplier_metrics.sort_values('risk_score', ascending=False)
    
    def seasonal_demand_analysis(self) -> Dict:
        """
        Analyze seasonal patterns in demand
        Returns monthly demand trends and seasonality index
        """
        consumption = self.inventory[self.inventory['transaction_type'] == 'consumption'].copy()
        consumption['quantity'] = consumption['quantity'].abs()
        consumption['month'] = consumption['transaction_date'].dt.month
        consumption['month_name'] = consumption['transaction_date'].dt.month_name()
        
        # Monthly demand
        monthly_demand = consumption.groupby(['month', 'month_name'])['quantity'].sum().reset_index()
        avg_monthly = monthly_demand['quantity'].mean()
        
        # Seasonality index
        monthly_demand['seasonality_index'] = (monthly_demand['quantity'] / avg_monthly * 100).round(1)
        
        # Identify peak and low seasons
        peak_month = monthly_demand.loc[monthly_demand['quantity'].idxmax()]
        low_month = monthly_demand.loc[monthly_demand['quantity'].idxmin()]
        
        # Calculate demand variability
        demand_cv = monthly_demand['quantity'].std() / monthly_demand['quantity'].mean() * 100
        
        return {
            'monthly_data': monthly_demand,
            'average_monthly_demand': round(avg_monthly, 0),
            'peak_month': peak_month['month_name'],
            'peak_demand': peak_month['quantity'],
            'low_month': low_month['month_name'],
            'low_demand': low_month['quantity'],
            'demand_variability_cv': round(demand_cv, 1),
            'seasonality_strength': 'High' if demand_cv > 30 else 'Medium' if demand_cv > 15 else 'Low'
        }
    
    def lead_time_analysis(self) -> Dict:
        """
        Comprehensive lead time analysis across suppliers and parts
        """
        po = self.purchase_orders.copy()
        
        if 'expected_delivery' not in po.columns or 'actual_delivery' not in po.columns:
            # Use lead_time_days from spare_parts
            lead_times = self.spare_parts[['part_id', 'lead_time_days', 'supplier_id']].copy()
            
            return {
                'avg_lead_time': lead_times['lead_time_days'].mean(),
                'lead_time_std': lead_times['lead_time_days'].std(),
                'min_lead_time': lead_times['lead_time_days'].min(),
                'max_lead_time': lead_times['lead_time_days'].max(),
                'lead_time_reliability': 'Data Limited'
            }
        
        po_delivered = po.dropna(subset=['expected_delivery', 'actual_delivery', 'order_date'])
        
        # Calculate planned vs actual lead time
        po_delivered['planned_lead_time'] = (po_delivered['expected_delivery'] - po_delivered['order_date']).dt.days
        po_delivered['actual_lead_time'] = (po_delivered['actual_delivery'] - po_delivered['order_date']).dt.days
        po_delivered['lead_time_variance'] = po_delivered['actual_lead_time'] - po_delivered['planned_lead_time']
        
        # By supplier
        supplier_lt = po_delivered.groupby('supplier_id').agg({
            'planned_lead_time': 'mean',
            'actual_lead_time': 'mean',
            'lead_time_variance': ['mean', 'std']
        }).reset_index()
        supplier_lt.columns = ['supplier_id', 'avg_planned_lt', 'avg_actual_lt', 'avg_variance', 'variance_std']
        
        return {
            'avg_planned_lead_time': po_delivered['planned_lead_time'].mean(),
            'avg_actual_lead_time': po_delivered['actual_lead_time'].mean(),
            'avg_lead_time_variance': po_delivered['lead_time_variance'].mean(),
            'lead_time_std': po_delivered['actual_lead_time'].std(),
            'on_time_rate': (po_delivered['lead_time_variance'] <= 0).mean() * 100,
            'supplier_analysis': supplier_lt
        }
    
    def inventory_health_score(self) -> Dict:
        """
        Calculate an overall inventory health score (0-100)
        Based on multiple indicators
        """
        dos_df = self.calculate_days_of_supply()
        fill_rate = self.calculate_fill_rate()
        
        # Component scores
        # 1. DOS Score (penalize extremes)
        avg_dos = dos_df['days_of_supply'].median()
        if avg_dos < 7:
            dos_score = 40  # Too low - stockout risk
        elif avg_dos < 15:
            dos_score = 70
        elif avg_dos < 45:
            dos_score = 100  # Optimal
        elif avg_dos < 90:
            dos_score = 70
        else:
            dos_score = 40  # Too high - excess inventory
        
        # 2. Fill Rate Score
        fill_score = min(fill_rate['fill_rate'], 100)
        
        # 3. Stock Distribution Score
        dos_status_counts = dos_df['dos_status'].value_counts(normalize=True) * 100
        optimal_pct = dos_status_counts.get('Optimal', 0)
        critical_pct = dos_status_counts.get('Critical - Reorder Now', 0)
        distribution_score = optimal_pct - (critical_pct * 2)  # Penalize critical items
        distribution_score = max(0, min(100, distribution_score))
        
        # Composite score
        health_score = (0.4 * dos_score + 0.35 * fill_score + 0.25 * distribution_score)
        
        return {
            'overall_health_score': round(health_score, 1),
            'dos_score': round(dos_score, 1),
            'fill_rate_score': round(fill_score, 1),
            'distribution_score': round(distribution_score, 1),
            'status': 'Excellent' if health_score >= 85 else 'Good' if health_score >= 70 else 'Fair' if health_score >= 50 else 'Poor',
            'dos_breakdown': dos_df['dos_status'].value_counts().to_dict(),
            'recommendations': self._get_inventory_recommendations(health_score, avg_dos, critical_pct)
        }
    
    def _get_inventory_recommendations(self, score: float, avg_dos: float, critical_pct: float) -> List[str]:
        """Generate inventory optimization recommendations"""
        recommendations = []
        
        if score < 70:
            recommendations.append("‚ö†Ô∏è Inventory health needs immediate attention")
        
        if avg_dos > 60:
            recommendations.append("üìâ Consider reducing safety stock levels to free up working capital")
        elif avg_dos < 15:
            recommendations.append("üìà Increase safety stock for critical items to prevent stockouts")
        
        if critical_pct > 10:
            recommendations.append(f"üö® {critical_pct:.0f}% of items are at critical DOS levels - expedite replenishment")
        
        return recommendations if recommendations else ["‚úÖ Inventory levels are well-optimized"]
    
    def _get_benchmark_status(self, metric: str, value: float) -> Dict:
        """Compare value against industry benchmarks"""
        benchmarks = self.BENCHMARKS.get(metric, {})
        
        if not benchmarks:
            return {'status': 'N/A', 'color': 'gray'}
        
        # For metrics where higher is better
        if metric in ['fill_rate', 'on_time_delivery', 'perfect_order_rate', 'oee', 'supplier_otd', 'inventory_turnover']:
            if value >= benchmarks['excellent']:
                return {'status': 'Excellent', 'color': '#00d2ff', 'icon': 'üèÜ'}
            elif value >= benchmarks['good']:
                return {'status': 'Good', 'color': '#5cb85c', 'icon': '‚úÖ'}
            elif value >= benchmarks['average']:
                return {'status': 'Average', 'color': '#f0ad4e', 'icon': 'üìä'}
            else:
                return {'status': 'Below Average', 'color': '#ff4b4b', 'icon': '‚ö†Ô∏è'}
        
        # For metrics where lower is better (days_of_supply)
        else:
            if value <= benchmarks['excellent']:
                return {'status': 'Excellent', 'color': '#00d2ff', 'icon': 'üèÜ'}
            elif value <= benchmarks['good']:
                return {'status': 'Good', 'color': '#5cb85c', 'icon': '‚úÖ'}
            elif value <= benchmarks['average']:
                return {'status': 'Average', 'color': '#f0ad4e', 'icon': 'üìä'}
            else:
                return {'status': 'Below Average', 'color': '#ff4b4b', 'icon': '‚ö†Ô∏è'}
    
    def correlation_analysis(self) -> pd.DataFrame:
        """
        Analyze correlations between key supply chain metrics
        """
        # Build a metrics dataframe per part
        metrics_df = self.spare_parts[['part_id', 'part_name', 'unit_cost', 'lead_time_days']].copy()
        
        # Add consumption data
        consumption = self.inventory[self.inventory['transaction_type'] == 'consumption'].copy()
        consumption['quantity'] = consumption['quantity'].abs()
        total_consumption = consumption.groupby('part_id')['quantity'].sum()
        metrics_df['total_consumption'] = metrics_df['part_id'].map(total_consumption).fillna(0)
        
        # Add stock levels
        stock_levels = self.inventory.groupby('part_id')['quantity'].sum()
        metrics_df['current_stock'] = metrics_df['part_id'].map(stock_levels).fillna(0).clip(lower=0)
        
        # Calculate correlations
        numeric_cols = ['unit_cost', 'lead_time_days', 'total_consumption', 'current_stock']
        correlation_matrix = metrics_df[numeric_cols].corr()
        
        return correlation_matrix
    
    def anomaly_detection(self) -> Dict:
        """
        Detect anomalies in key metrics using statistical methods
        """
        anomalies = {}
        
        # 1. Consumption anomalies (Z-score > 2)
        consumption = self.inventory[self.inventory['transaction_type'] == 'consumption'].copy()
        consumption['quantity'] = consumption['quantity'].abs()
        monthly_consumption = consumption.groupby(consumption['transaction_date'].dt.to_period('M'))['quantity'].sum()
        
        if len(monthly_consumption) > 3:
            z_scores = stats.zscore(monthly_consumption)
            anomaly_months = monthly_consumption[abs(z_scores) > 2]
            anomalies['consumption'] = {
                'count': len(anomaly_months),
                'periods': [str(p) for p in anomaly_months.index.tolist()],
                'interpretation': 'Months with unusually high or low consumption'
            }
        
        # 2. Lead time anomalies
        if 'lead_time_days' in self.spare_parts.columns:
            lt_zscores = stats.zscore(self.spare_parts['lead_time_days'].dropna())
            anomaly_parts = self.spare_parts[abs(lt_zscores) > 2]
            anomalies['lead_time'] = {
                'count': len(anomaly_parts),
                'parts': anomaly_parts['part_name'].tolist()[:5],
                'interpretation': 'Parts with unusually long or short lead times'
            }
        
        # 3. Cost anomalies
        if 'unit_cost' in self.spare_parts.columns:
            cost_zscores = stats.zscore(self.spare_parts['unit_cost'].dropna())
            cost_anomalies = self.spare_parts[abs(cost_zscores) > 2]
            anomalies['cost'] = {
                'count': len(cost_anomalies),
                'parts': cost_anomalies['part_name'].tolist()[:5],
                'interpretation': 'Parts with unusually high or low unit costs'
            }
        
        return anomalies
    
    def what_if_analysis(self, scenario: str, change_pct: float = 10) -> Dict:
        """
        Perform what-if scenario analysis
        
        Scenarios:
        - 'demand_increase': Impact of demand increase
        - 'lead_time_increase': Impact of longer lead times
        - 'cost_increase': Impact of price increases
        - 'supplier_failure': Impact of losing a supplier
        """
        results = {}
        
        if scenario == 'demand_increase':
            current_dos = self.calculate_days_of_supply()
            new_dos = current_dos['days_of_supply'] * (100 / (100 + change_pct))
            
            current_critical = (current_dos['dos_status'] == 'Critical - Reorder Now').sum()
            new_critical = (new_dos < 7).sum()
            
            results = {
                'scenario': f'{change_pct}% Demand Increase',
                'current_critical_items': current_critical,
                'projected_critical_items': new_critical,
                'additional_stockout_risk': new_critical - current_critical,
                'recommendation': f'Increase safety stock by {change_pct}% for high-velocity items'
            }
        
        elif scenario == 'lead_time_increase':
            current_lt = self.spare_parts['lead_time_days'].mean()
            new_lt = current_lt * (1 + change_pct / 100)
            
            # Impact on reorder point
            reorder_increase = new_lt - current_lt
            
            results = {
                'scenario': f'{change_pct}% Lead Time Increase',
                'current_avg_lead_time': round(current_lt, 1),
                'projected_lead_time': round(new_lt, 1),
                'reorder_point_increase_days': round(reorder_increase, 1),
                'recommendation': f'Increase reorder points by {reorder_increase:.0f} days worth of stock'
            }
        
        elif scenario == 'cost_increase':
            current_value = (self.spare_parts['unit_cost'] * 100).sum()  # Assume 100 units each
            new_value = current_value * (1 + change_pct / 100)
            
            results = {
                'scenario': f'{change_pct}% Cost Increase',
                'current_inventory_value': f'‚Çπ{current_value:,.0f}',
                'projected_inventory_value': f'‚Çπ{new_value:,.0f}',
                'additional_working_capital': f'‚Çπ{new_value - current_value:,.0f}',
                'recommendation': 'Review inventory optimization to offset cost increases'
            }
        
        elif scenario == 'supplier_failure':
            supplier_risk = self.calculate_supplier_risk_score()
            highest_spend_supplier = supplier_risk.nlargest(1, 'total_spend').iloc[0]
            
            affected_parts = self.spare_parts[self.spare_parts['supplier_id'] == highest_spend_supplier['supplier_id']]
            
            results = {
                'scenario': 'Loss of Highest-Spend Supplier',
                'supplier_name': highest_spend_supplier['supplier_name'],
                'spend_at_risk': f"‚Çπ{highest_spend_supplier['total_spend']:,.0f}",
                'parts_affected': len(affected_parts),
                'affected_part_names': affected_parts['part_name'].tolist()[:5],
                'recommendation': 'Develop alternative supplier relationships for critical parts'
            }
        
        return results


class TrendAnalysis:
    """
    Statistical trend analysis for key metrics
    """
    
    @staticmethod
    def calculate_trend(data: pd.Series) -> Dict:
        """
        Calculate linear trend and statistics
        """
        if len(data) < 3:
            return {'trend': 'Insufficient data', 'slope': 0, 'significant': False}
        
        x = np.arange(len(data))
        slope, intercept, r_value, p_value, std_err = stats.linregress(x, data)
        
        trend_direction = 'Increasing' if slope > 0 else 'Decreasing' if slope < 0 else 'Stable'
        
        return {
            'trend': trend_direction,
            'slope': round(slope, 4),
            'r_squared': round(r_value ** 2, 4),
            'p_value': round(p_value, 4),
            'significant': p_value < 0.05,
            'monthly_change': round(slope, 2),
            'confidence': 'High' if p_value < 0.05 else 'Medium' if p_value < 0.1 else 'Low'
        }
    
    @staticmethod
    def detect_trend_change(data: pd.Series, window: int = 3) -> Dict:
        """
        Detect if there's been a recent change in trend
        """
        if len(data) < window * 2:
            return {'change_detected': False, 'reason': 'Insufficient data'}
        
        recent = data.iloc[-window:]
        previous = data.iloc[-window*2:-window]
        
        recent_mean = recent.mean()
        previous_mean = previous.mean()
        
        pct_change = (recent_mean - previous_mean) / previous_mean * 100 if previous_mean != 0 else 0
        
        change_detected = abs(pct_change) > 15  # More than 15% change
        
        return {
            'change_detected': change_detected,
            'recent_mean': round(recent_mean, 2),
            'previous_mean': round(previous_mean, 2),
            'pct_change': round(pct_change, 2),
            'direction': 'Increase' if pct_change > 0 else 'Decrease'
        }
